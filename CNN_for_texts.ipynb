{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shinobu9/mipt-ml-course/blob/main/CNN_for_texts.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "13pL--6rycN3"
      },
      "source": [
        "## Homework02: Three headed network in PyTorch\n",
        "\n",
        "This notebook accompanies the [week02](https://github.com/girafe-ai/natural-language-processing/tree/master/week02_cnn_for_texts) practice session. Refer to that notebook for more comments.\n",
        "\n",
        "All the preprocessing is the same as in the classwork. *Including the data leakage in the train test split (it's still for bonus points).*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 177,
      "metadata": {
        "id": "P8zS7m-gycN5"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import nltk\n",
        "import tqdm\n",
        "from collections import Counter"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MK4as690dIuB"
      },
      "source": [
        "If you have already downloaded the data on the Seminar, simply run through the next cells. Otherwise uncomment the next cell (and comment the another one ;)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 178,
      "metadata": {
        "id": "G0c5OyaSdIuB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f685f5bc-afc1-48be-ff1d-7d55a0bc973f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100    17    0    17    0     0    116      0 --:--:-- --:--:-- --:--:--   115\n",
            "100   342  100   342    0     0    585      0 --:--:-- --:--:-- --:--:--   585\n",
            "100  119M  100  119M    0     0  34.0M      0  0:00:03  0:00:03 --:--:-- 63.1M\n",
            "Train_rev1.csv\n",
            "--2023-04-02 13:39:56--  https://raw.githubusercontent.com/girafe-ai/natural-language-processing/22f_msai/homeworks/assignment02_three_headed_network/network.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1469 (1.4K) [text/plain]\n",
            "Saving to: ‘network.py.2’\n",
            "\n",
            "network.py.2        100%[===================>]   1.43K  --.-KB/s    in 0s      \n",
            "\n",
            "2023-04-02 13:39:56 (28.6 MB/s) - ‘network.py.2’ saved [1469/1469]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# uncomment and run this cell, if you don't have data locally yet.\n",
        "\n",
        "!curl -L \"https://www.dropbox.com/s/5msc5ix7ndyba10/Train_rev1.csv.tar.gz?dl=1\" -o Train_rev1.csv.tar.gz\n",
        "!tar -xvzf ./Train_rev1.csv.tar.gz\n",
        "\n",
        "data = pd.read_csv(\"./Train_rev1.csv\", index_col=None)\n",
        "\n",
        "!wget https://raw.githubusercontent.com/girafe-ai/natural-language-processing/22f_msai/homeworks/assignment02_three_headed_network/network.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vwN72gd4ycOA"
      },
      "outputs": [],
      "source": [
        "# run this cell if you have downloaded the dataset on the seminar\n",
        "data = pd.read_csv(\"../../week02_CNN_n_Vanishing_gradient/Train_rev1.csv\", index_col=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 179,
      "metadata": {
        "id": "UuuKIKfrycOH"
      },
      "outputs": [],
      "source": [
        "data['Log1pSalary'] = np.log1p(data['SalaryNormalized']).astype('float32')\n",
        "text_columns = [\"Title\", \"FullDescription\"]\n",
        "categorical_columns = [\"Category\", \"Company\", \"LocationNormalized\", \"ContractType\", \"ContractTime\"]\n",
        "target_column = \"Log1pSalary\"\n",
        "\n",
        "data[categorical_columns] = data[categorical_columns].fillna('NaN') # cast missing values to string \"NaN\"\n",
        "\n",
        "data.sample(3)\n",
        "\n",
        "\n",
        "data_for_autotest = data[-5000:]\n",
        "data = data[:-5000]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 180,
      "metadata": {
        "id": "RUWkpd7PycOQ",
        "outputId": "43de4b6b-6680-4a08-d93b-51a057c4a529",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenized:\n",
            "2         mathematical modeller / simulation analyst / o...\n",
            "100002    a successful and high achieving specialist sch...\n",
            "200002    web designer html , css , javascript , photosh...\n",
            "Name: FullDescription, dtype: object\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "239768it [00:31, 7530.54it/s] \n"
          ]
        }
      ],
      "source": [
        "tokenizer = nltk.tokenize.WordPunctTokenizer()\n",
        "# see task above\n",
        "def normalize(text):\n",
        "    text = str(text).lower()\n",
        "    return ' '.join(tokenizer.tokenize(text))\n",
        "    \n",
        "data[text_columns] = data[text_columns].applymap(normalize)\n",
        "\n",
        "print(\"Tokenized:\")\n",
        "print(data[\"FullDescription\"][2::100000])\n",
        "assert data[\"FullDescription\"][2][:50] == 'mathematical modeller / simulation analyst / opera'\n",
        "assert data[\"Title\"][54321] == 'international digital account manager ( german )'\n",
        "\n",
        "# Count how many times does each token occur in both \"Title\" and \"FullDescription\" in total\n",
        "# build a dictionary { token -> it's count }\n",
        "from collections import Counter\n",
        "from tqdm import tqdm as tqdm\n",
        "\n",
        "token_counts = Counter()\n",
        "for _, row in tqdm(data[text_columns].iterrows()):\n",
        "    for string in row:\n",
        "        token_counts.update(string.split())\n",
        "\n",
        "# hint: you may or may not want to use collections.Counter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 181,
      "metadata": {
        "id": "k5b6CDfRdIuD",
        "outputId": "b72ac0cc-7605-4c45-a221-89a239da539f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2598827"
            ]
          },
          "metadata": {},
          "execution_count": 181
        }
      ],
      "source": [
        "token_counts.most_common(1)[0][1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 182,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GiOWbc15ycOb",
        "outputId": "38d71b5b-880a-4c5a-d756-d1d5823ac94a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total unique tokens : 201127\n",
            "('and', 2598827)\n",
            "('.', 2471477)\n",
            "(',', 2266256)\n",
            "('the', 2036428)\n",
            "('to', 1977039)\n",
            "...\n",
            "('dbms_stats', 1)\n",
            "('dbms_output', 1)\n",
            "('dbms_job', 1)\n",
            "Correct!\n",
            "Vocabulary size: 33795\n",
            "Correct!\n",
            "Correct!\n"
          ]
        }
      ],
      "source": [
        "print(\"Total unique tokens :\", len(token_counts))\n",
        "print('\\n'.join(map(str, token_counts.most_common(n=5))))\n",
        "print('...')\n",
        "print('\\n'.join(map(str, token_counts.most_common()[-3:])))\n",
        "\n",
        "assert token_counts.most_common(1)[0][1] in  range(2500000, 2700000)\n",
        "assert len(token_counts) in range(200000, 210000)\n",
        "print('Correct!')\n",
        "\n",
        "min_count = 10\n",
        "\n",
        "# tokens from token_counts keys that had at least min_count occurrences throughout the dataset\n",
        "tokens = [token for token, count in token_counts.items() if count >= min_count]# <YOUR CODE HERE>\n",
        "# Add a special tokens for unknown and empty words\n",
        "UNK, PAD = \"UNK\", \"PAD\"\n",
        "tokens = [UNK, PAD] + sorted(tokens)\n",
        "print(\"Vocabulary size:\", len(tokens))\n",
        "\n",
        "assert type(tokens) == list\n",
        "assert len(tokens) in range(32000, 35000)\n",
        "assert 'me' in tokens\n",
        "assert UNK in tokens\n",
        "print(\"Correct!\")\n",
        "\n",
        "token_to_id = {token: idx for idx, token in enumerate(tokens)}\n",
        "assert isinstance(token_to_id, dict)\n",
        "assert len(token_to_id) == len(tokens)\n",
        "for tok in tokens:\n",
        "    assert tokens[token_to_id[tok]] == tok\n",
        "\n",
        "print(\"Correct!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 183,
      "metadata": {
        "id": "JEsLeBjVycOw"
      },
      "outputs": [],
      "source": [
        "UNK_IX, PAD_IX = map(token_to_id.get, [UNK, PAD])\n",
        "\n",
        "def as_matrix(sequences, max_len=None):\n",
        "    \"\"\" Convert a list of tokens into a matrix with padding \"\"\"\n",
        "    if isinstance(sequences[0], str):\n",
        "        sequences = list(map(str.split, sequences))\n",
        "        \n",
        "    max_len = min(max(map(len, sequences)), max_len or float('inf'))\n",
        "    \n",
        "    matrix = np.full((len(sequences), max_len), np.int32(PAD_IX))\n",
        "    for i,seq in enumerate(sequences):\n",
        "        row_ix = [token_to_id.get(word, UNK_IX) for word in seq[:max_len]]\n",
        "        matrix[i, :len(row_ix)] = row_ix\n",
        "    \n",
        "    return matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 184,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JiBlPkdKycOy",
        "outputId": "bc0a548c-a75f-4a71-a940-652c3087b93e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lines:\n",
            "engineering systems analyst\n",
            "hr assistant\n",
            "senior ec & i engineer\n",
            "\n",
            "Matrix:\n",
            "[[10705 29830  2143     1     1]\n",
            " [14875  2817     1     1     1]\n",
            " [27345 10107    15 15069 10702]]\n"
          ]
        }
      ],
      "source": [
        "print(\"Lines:\")\n",
        "print('\\n'.join(data[\"Title\"][::100000].values), end='\\n\\n')\n",
        "print(\"Matrix:\")\n",
        "print(as_matrix(data[\"Title\"][::100000]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 185,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "DpOlBp7ZycO6",
        "outputId": "8a958b6e-82bb-4d14-b558-21e17dfbeba3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DictVectorizer(dtype=<class 'numpy.float32'>, sparse=False)"
            ],
            "text/html": [
              "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DictVectorizer(dtype=&lt;class &#x27;numpy.float32&#x27;&gt;, sparse=False)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DictVectorizer</label><div class=\"sk-toggleable__content\"><pre>DictVectorizer(dtype=&lt;class &#x27;numpy.float32&#x27;&gt;, sparse=False)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 185
        }
      ],
      "source": [
        "from sklearn.feature_extraction import DictVectorizer\n",
        "\n",
        "# we only consider top-1k most frequent companies to minimize memory usage\n",
        "top_companies, top_counts = zip(*Counter(data['Company']).most_common(1000))\n",
        "recognized_companies = set(top_companies)\n",
        "data[\"Company\"] = data[\"Company\"].apply(lambda comp: comp if comp in recognized_companies else \"Other\")\n",
        "\n",
        "categorical_vectorizer = DictVectorizer(dtype=np.float32, sparse=False)\n",
        "categorical_vectorizer.fit(data[categorical_columns].apply(dict, axis=1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yk4jmtAYycO8"
      },
      "source": [
        "### The deep learning part\n",
        "\n",
        "Once we've learned to tokenize the data, let's design a machine learning experiment.\n",
        "\n",
        "As before, we won't focus too much on validation, opting for a simple train-test split.\n",
        "\n",
        "__To be completely rigorous,__ we've comitted a small crime here: we used the whole data for tokenization and vocabulary building. A more strict way would be to do that part on training set only. You may want to do that and measure the magnitude of changes.\n",
        "\n",
        "\n",
        "#### Here comes the simple one-headed network from the seminar. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 186,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TngLcWA0ycO_",
        "outputId": "6452362b-69ce-4439-8d14-aa8cbc75cef2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train size =  191814\n",
            "Validation size =  47954\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "data_train, data_val = train_test_split(data, test_size=0.2, random_state=42)\n",
        "data_train.index = range(len(data_train))\n",
        "data_val.index = range(len(data_val))\n",
        "\n",
        "print(\"Train size = \", len(data_train))\n",
        "print(\"Validation size = \", len(data_val))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 187,
      "metadata": {
        "id": "2PXuKgOSycPB"
      },
      "outputs": [],
      "source": [
        "def make_batch(data, max_len=None, word_dropout=0):\n",
        "    \"\"\"\n",
        "    Creates a keras-friendly dict from the batch data.\n",
        "    :param word_dropout: replaces token index with UNK_IX with this probability\n",
        "    :returns: a dict with {'title' : int64[batch, title_max_len]\n",
        "    \"\"\"\n",
        "    batch = {}\n",
        "    batch[\"Title\"] = as_matrix(data[\"Title\"].values, max_len)\n",
        "    batch[\"FullDescription\"] = as_matrix(data[\"FullDescription\"].values, max_len)\n",
        "    batch['Categorical'] = categorical_vectorizer.transform(data[categorical_columns].apply(dict, axis=1))\n",
        "    \n",
        "    if word_dropout != 0:\n",
        "        batch[\"FullDescription\"] = apply_word_dropout(batch[\"FullDescription\"], 1. - word_dropout)\n",
        "    \n",
        "    if target_column in data.columns:\n",
        "        batch[target_column] = data[target_column].values\n",
        "    \n",
        "    return batch\n",
        "\n",
        "def apply_word_dropout(matrix, keep_prop, replace_with=UNK_IX, pad_ix=PAD_IX,):\n",
        "    dropout_mask = np.random.choice(2, np.shape(matrix), p=[keep_prop, 1 - keep_prop])\n",
        "    dropout_mask &= matrix != pad_ix\n",
        "    return np.choose(dropout_mask, [matrix, np.full_like(matrix, replace_with)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 188,
      "metadata": {
        "id": "I6LpEQf0ycPD"
      },
      "outputs": [],
      "source": [
        "a = make_batch(data_train[:3], max_len=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UHCjwwTIdIuE"
      },
      "source": [
        "But to start with let's build the simple model using only the part of the data. Let's create the baseline solution using only the description part (so it should definetely fit into the Sequential model)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 189,
      "metadata": {
        "id": "XPswwuN3dIuE"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 190,
      "metadata": {
        "id": "gvQNVH_RdIuE"
      },
      "outputs": [],
      "source": [
        "# You will need these to make it simple\n",
        "\n",
        "class Flatten(nn.Module):\n",
        "    def forward(self, input):\n",
        "        return input.view(input.size(0), -1)\n",
        "\n",
        "class Reorder(nn.Module):\n",
        "    def forward(self, input):\n",
        "        return input.permute((0, 2, 1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y_n5WMH_dIuE"
      },
      "source": [
        "To generate minibatches we will use simple pyton generator."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 191,
      "metadata": {
        "id": "K_cIHbaGdIuE"
      },
      "outputs": [],
      "source": [
        "def iterate_minibatches(data, batch_size=256, shuffle=True, cycle=False, **kwargs):\n",
        "    \"\"\" iterates minibatches of data in random order \"\"\"\n",
        "    while True:\n",
        "        indices = np.arange(len(data))\n",
        "        if shuffle:\n",
        "            indices = np.random.permutation(indices)\n",
        "\n",
        "        for start in range(0, len(indices), batch_size):\n",
        "            batch = make_batch(data.iloc[indices[start : start + batch_size]], **kwargs)\n",
        "            target = batch.pop(target_column)\n",
        "            yield batch, target\n",
        "        \n",
        "        if not cycle: break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 192,
      "metadata": {
        "id": "LG3z22sYdIuE"
      },
      "outputs": [],
      "source": [
        "iterator = iterate_minibatches(data_train, 3)\n",
        "batch, target = next(iterator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 193,
      "metadata": {
        "id": "dWtgQ0nmdIuE"
      },
      "outputs": [],
      "source": [
        "# Here is some startup code:\n",
        "n_tokens=len(tokens)\n",
        "n_cat_features=len(categorical_vectorizer.vocabulary_)\n",
        "hid_size=64\n",
        "simple_model = nn.Sequential()\n",
        "\n",
        "simple_model.add_module('emb', nn.Embedding(num_embeddings=n_tokens, embedding_dim=hid_size))\n",
        "simple_model.add_module('reorder', Reorder())\n",
        "simple_model.add_module('conv1', nn.Conv1d(\n",
        "    in_channels=hid_size,\n",
        "    out_channels=hid_size,\n",
        "    kernel_size=2)\n",
        "                       )\n",
        "simple_model.add_module('relu1', nn.ReLU())\n",
        "simple_model.add_module('adapt_avg_pool', nn.AdaptiveAvgPool1d(output_size=1))\n",
        "simple_model.add_module('flatten1', Flatten())\n",
        "simple_model.add_module('linear1', nn.Linear(in_features=hid_size, out_features=1))\n",
        "# <YOUR CODE HERE>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lZLi_9oOdIuF"
      },
      "source": [
        "__Remember!__ We are working with regression problem and predicting only one number."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 194,
      "metadata": {
        "id": "vfLemcVSdIuF",
        "outputId": "2e2990d8-2634-435f-f288-61500a2d1c1b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.0308],\n",
              "        [-0.0139],\n",
              "        [ 0.0016]], grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 194
        }
      ],
      "source": [
        "# Try this to check your model. `torch.long` tensors are required for nn.Embedding layers.\n",
        "simple_model(torch.tensor(batch['FullDescription'], dtype=torch.long))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 195,
      "metadata": {
        "id": "K4grVPZidIuF",
        "outputId": "6a2838ff-f988-4140-914d-a1d91e15aca0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3, 297)"
            ]
          },
          "metadata": {},
          "execution_count": 195
        }
      ],
      "source": [
        "batch['FullDescription'].shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LcRh8oe-dIuF"
      },
      "source": [
        "And now simple training pipeline (it's commented because we've already done that in class. No need to do it again)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 196,
      "metadata": {
        "id": "DoeVXa6DdIuF",
        "outputId": "26688aea-984a-4e49-8854-564e452569b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 389
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-196-e3849248e340>\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    202\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    311\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 313\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    314\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    307\u001b[0m                             \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m                             _single(0), self.dilation, self.groups)\n\u001b[0;32m--> 309\u001b[0;31m         return F.conv1d(input, weight, bias, self.stride,\n\u001b[0m\u001b[1;32m    310\u001b[0m                         self.padding, self.dilation, self.groups)\n\u001b[1;32m    311\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "from IPython.display import clear_output\n",
        "from random import sample\n",
        "\n",
        "epochs = 1\n",
        "\n",
        "model = simple_model\n",
        "opt = torch.optim.Adam(model.parameters())\n",
        "loss_func = nn.MSELoss()\n",
        "\n",
        "history = []\n",
        "for epoch_num in range(epochs):\n",
        "    for idx, (batch, target) in enumerate(iterate_minibatches(data_train)):\n",
        "        # Preprocessing the batch data and target\n",
        "        batch = torch.tensor(batch['FullDescription'], dtype=torch.long)\n",
        "\n",
        "        target = torch.tensor(target)\n",
        "\n",
        "\n",
        "        predictions = model(batch)\n",
        "        predictions = predictions.view(predictions.size(0))\n",
        "\n",
        "        loss = loss_func(predictions, target)# <YOUR CODE HERE>\n",
        "\n",
        "        # train with backprop\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "        opt.zero_grad()\n",
        "        # <YOUR CODE HERE>\n",
        "\n",
        "        history.append(loss.data.numpy())\n",
        "        if (idx+1)%10==0:\n",
        "            clear_output(True)\n",
        "            plt.plot(history,label='loss')\n",
        "            plt.legend()\n",
        "            plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DllwrUlJdIuF"
      },
      "source": [
        "### Actual homework starts here\n",
        "__Your ultimate task is to code the three headed network described on the picture below.__ \n",
        "To make it closer to the real world, please store the network code in file `network.py` in this directory. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0eI5h9UMycPF"
      },
      "source": [
        "#### Architecture\n",
        "\n",
        "Our main model consists of three branches:\n",
        "* Title encoder\n",
        "* Description encoder\n",
        "* Categorical features encoder\n",
        "\n",
        "We will then feed all 3 branches into one common network that predicts salary.\n",
        "\n",
        "<img src=\"https://github.com/yandexdataschool/nlp_course/raw/master/resources/w2_conv_arch.png\" width=600px>\n",
        "\n",
        "This clearly doesn't fit into PyTorch __Sequential__ interface. To build such a network, one will have to use [__PyTorch nn.Module API__](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 203,
      "metadata": {
        "id": "JhjjAiCXdIuF"
      },
      "outputs": [],
      "source": [
        "import network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 214,
      "metadata": {
        "id": "t6-2-HdZdIuF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7af8a59c-a7e5-4ebe-f795-580433f0ec4b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<module 'network' from '/content/network.py'>"
            ]
          },
          "metadata": {},
          "execution_count": 214
        }
      ],
      "source": [
        "# Re-run this cell if you updated the file with network source code\n",
        "import imp\n",
        "imp.reload(network)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 215,
      "metadata": {
        "id": "8Cov9HOidIuF"
      },
      "outputs": [],
      "source": [
        "model = network.ThreeInputsNet(\n",
        "    n_tokens=len(tokens),\n",
        "    n_cat_features=len(categorical_vectorizer.vocabulary_),\n",
        "\n",
        "    # this parameter defines the number of the inputs in the layer,\n",
        "    # which stands after the concatenation. In should be found out by you.\n",
        "    concat_number_of_features=64*3,\n",
        "    hid_size=64\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 216,
      "metadata": {
        "id": "IseKf1vVdIuF"
      },
      "outputs": [],
      "source": [
        "testing_batch, _ = next(iterate_minibatches(data_train, 3))\n",
        "testing_batch = [\n",
        "    torch.tensor(testing_batch['Title'], dtype=torch.long),\n",
        "    torch.tensor(testing_batch['FullDescription'], dtype=torch.long),\n",
        "    torch.tensor(testing_batch['Categorical'])\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 217,
      "metadata": {
        "id": "zNmAsx7BdIuF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "301ec5ba-966e-4a49-f18c-d09c92f62880"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seems fine!\n"
          ]
        }
      ],
      "source": [
        "assert model(testing_batch).shape == torch.Size([3, 1])\n",
        "assert model(testing_batch).dtype == torch.float32\n",
        "print('Seems fine!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dYchQmvldIuF"
      },
      "source": [
        "Now train the network for a while (100 batches would be fine)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 218,
      "metadata": {
        "id": "al8wu5u6dIuG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "outputId": "4e7f8b4b-72a3-44c5-cdd1-c7d972fc3852"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Training pipeline comes here (almost the same as for the simple_model)\n",
        "from IPython.display import clear_output\n",
        "from random import sample\n",
        "\n",
        "epochs = 1\n",
        "\n",
        "opt = torch.optim.Adam(model.parameters())\n",
        "loss_func = nn.MSELoss()\n",
        "\n",
        "history = []\n",
        "for epoch_num in range(epochs):\n",
        "    for idx, (batch, target) in enumerate(iterate_minibatches(data_train, 64)):\n",
        "        # Preprocessing the batch data and target\n",
        "        batch = [\n",
        "            torch.tensor(batch['Title'], dtype=torch.long),\n",
        "            torch.tensor(batch['FullDescription'], dtype=torch.long),\n",
        "            torch.tensor(batch['Categorical'])\n",
        "        ]\n",
        "        target = torch.tensor(target)\n",
        "        predictions = model(batch)\n",
        "        predictions = predictions.view(predictions.size(0))\n",
        "\n",
        "        loss = loss_func(predictions, target)# <YOUR CODE HERE>\n",
        "\n",
        "        # train with backprop\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "        opt.zero_grad()\n",
        "        # <YOUR CODE HERE>\n",
        "\n",
        "        history.append(loss.data.numpy())\n",
        "        if (idx+1)%10==0:\n",
        "            clear_output(True)\n",
        "            plt.plot(history,label='loss')\n",
        "            plt.legend()\n",
        "            plt.show()\n",
        "        # if idx==100: break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nFPEUCz-dIuG"
      },
      "source": [
        "Now, to evaluate the model it can be switched to `eval` state."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 219,
      "metadata": {
        "id": "BGqV__JTdIuG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e098489-1ecf-4a54-ceb3-c3478430f011"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ThreeInputsNet(\n",
              "  (title_emb): Embedding(33795, 64)\n",
              "  (title_conv): Conv1d(64, 64, kernel_size=(2,), stride=(1,))\n",
              "  (title_pool): AdaptiveAvgPool1d(output_size=1)\n",
              "  (full_emb): Embedding(33795, 64)\n",
              "  (full_conv): Conv1d(64, 64, kernel_size=(2,), stride=(1,))\n",
              "  (full_pool): AdaptiveAvgPool1d(output_size=1)\n",
              "  (category_out): Linear(in_features=3746, out_features=64, bias=True)\n",
              "  (inter_dense): Linear(in_features=192, out_features=128, bias=True)\n",
              "  (final_dense): Linear(in_features=128, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 219
        }
      ],
      "source": [
        "model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 220,
      "metadata": {
        "id": "TJMnJu02dIuG"
      },
      "outputs": [],
      "source": [
        "def generate_submission(model, data, batch_size=256, name=\"\", three_inputs_mode=True, **kw):\n",
        "    squared_error = abs_error = num_samples = 0.0\n",
        "    output_list = []\n",
        "    for batch_x, batch_y in tqdm(iterate_minibatches(data, batch_size=batch_size, shuffle=False, **kw)):\n",
        "        if three_inputs_mode:\n",
        "            batch = [\n",
        "                torch.tensor(batch_x['Title'], dtype=torch.long),\n",
        "                torch.tensor(batch_x['FullDescription'], dtype=torch.long),\n",
        "                torch.tensor(batch_x['Categorical'])\n",
        "            ]\n",
        "        else:\n",
        "            batch = torch.tensor(batch_x['FullDescription'], dtype=torch.long)\n",
        "\n",
        "        batch_pred = model(batch)[:, 0].detach().numpy()\n",
        "        \n",
        "        output_list.append((list(batch_pred), list(batch_y)))\n",
        "        \n",
        "        squared_error += np.sum(np.square(batch_pred - batch_y))\n",
        "        abs_error += np.sum(np.abs(batch_pred - batch_y))\n",
        "        num_samples += len(batch_y)\n",
        "    print(\"%s results:\" % (name or \"\"))\n",
        "    print(\"Mean square error: %.5f\" % (squared_error / num_samples))\n",
        "    print(\"Mean absolute error: %.5f\" % (abs_error / num_samples))\n",
        "    \n",
        "\n",
        "    batch_pred = [c for x in output_list for c in x[0]]\n",
        "    batch_y = [c for x in output_list for c in x[1]]\n",
        "    output_df = pd.DataFrame(list(zip(batch_pred, batch_y)), columns=['batch_pred', 'batch_y'])\n",
        "    output_df.to_csv('submission.csv', index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 223,
      "metadata": {
        "id": "NKjTiB6_dIuG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "350fc76f-517c-463e-9c2e-edced3b8fb9d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "20it [00:03,  6.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Submission results:\n",
            "Mean square error: 0.24407\n",
            "Mean absolute error: 0.40067\n",
            "Submission file generated\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "generate_submission(model, data_for_autotest, name='Submission')\n",
        "print('Submission file generated')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "utbsD869dIuG"
      },
      "source": [
        "__Both the notebook and the `.py` file are required to submit this homework.__"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "98e2-vD8Ln_d"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Py3 research env",
      "language": "python",
      "name": "py3_research"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}